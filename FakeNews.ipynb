{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441d9aa9-76b1-49ef-8437-6cdd64000dad",
   "metadata": {},
   "source": [
    "FAKE NEWS DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78935780-42fe-4d4f-989a-c8d61cbf04ab",
   "metadata": {},
   "source": [
    "Fake news refers to false or misleading information presented as genuine news. This misinformation can be spread through traditional media outlets, social media platforms, websites, or other channels. Fake news often aims to deceive readers or viewers for various reasons, including political manipulation, sensationalism, profit, or malicious intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4159ae0e-709a-46f9-9918-b8eb242d2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harb\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harb\\AppData\\Local\\Temp\\ipykernel_5860\\846528260.py:17: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import pprint\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e1be3-a3a1-4ae8-9ef1-71adc6cb3804",
   "metadata": {},
   "source": [
    "The dataset used is an online  News dataset that has two classes which are labelled 'FAKE' or 'REAL'. This dataset has different text that are mainly related to candidates for presidential elections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995ecca6-b916-475b-98c9-b14fa14bc4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data \n",
    "data = pd.read_csv(\"news.csv\") \n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f386118a-922b-4974-9318-41ec9c9e8e4a",
   "metadata": {},
   "source": [
    "After the dataset visualization, we have decided to drop the second column because the infromation in there wasn't relevant for our data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949c671b-fab1-4e1f-89b9-235145a8d65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop([\"Unnamed: 0\"], axis=1) \n",
    "data.head(5) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "be538618-15c2-4006-9c83-4a7cb18ad177",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2bef6c6-7996-4c8b-ac4d-324e7534dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the labels \n",
    "le = preprocessing.LabelEncoder() \n",
    "le.fit(data['label']) \n",
    "data['label'] = le.transform(data['label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a341c9c-1ad8-4baa-8f14-cd823fcb9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "max_length = 54\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "#This is a token used to represent out-of-vocabulary (OOV) words. These are words that are not found in the vocabulary during tokenization. \n",
    "#Using <OOV> as the token allows the model to handle words that it hasn't seen before.\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 3000\n",
    "test_portion = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b15193b-d0d4-47c0-9e40-aafb1c1684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [] \n",
    "text = [] \n",
    "labels = [] \n",
    "for x in range(training_size): \n",
    "\ttitle.append(data['title'][x]) \n",
    "\ttext.append(data['text'][x]) \n",
    "\tlabels.append(data['label'][x]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae3bd4-6de0-409e-9280-bddbe7045443",
   "metadata": {},
   "source": [
    "These parameters are commonly used in natural language processing (NLP) tasks, especially when working with text data for tasks like text classification or sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1845690e-65cd-4b65-8050-59a46eae7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the embeddings\n",
    "tokenizer1 = Tokenizer() \n",
    "tokenizer1.fit_on_texts(title) \n",
    "word_index1 = tokenizer1.word_index \n",
    "vocab_size1 = len(word_index1) \n",
    "sequences1 = tokenizer1.texts_to_sequences(title) \n",
    "padded1 = pad_sequences( \n",
    "\tsequences1, padding=padding_type, truncating=trunc_type) \n",
    "split = int(test_portion * training_size) \n",
    "training_sequences1 = padded1[split:training_size] \n",
    "test_sequences1 = padded1[0:split] \n",
    "test_labels = labels[0:split] \n",
    "training_labels = labels[split:training_size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29f0384-846b-499e-b6da-b3fc5d1be941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the original GloVe vectors file\n",
    "with open('glove.6B.50d.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Insert header line with vocabulary size and vector size\n",
    "lines.insert(0, f'{len(lines)} 50\\n')\n",
    "\n",
    "# Save the modified file\n",
    "with open('corrected_glove.6B.50d.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ab6cd6-c439-4524-8ab6-f875a9f29c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load GloVe vectors with explicit encoding\n",
    "embeddings_index = {} \n",
    "with open('corrected_glove.6B.50d.txt', encoding='utf-8') as f: \n",
    "    for line in f: \n",
    "        values = line.split() \n",
    "        word = values[0] \n",
    "        coefs = np.asarray(values[1:], dtype='float32') \n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "# Generating embeddings \n",
    "embeddings_matrix = np.zeros((vocab_size1+1, embedding_dim)) \n",
    "for word, i in word_index1.items(): \n",
    "\tembedding_vector = embeddings_index.get(word) \n",
    "\tif embedding_vector is not None: \n",
    "\t\tembeddings_matrix[i] = embedding_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d7dcbb5-07d2-42aa-9ff1-260d9e14ecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harb\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harb\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harb\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 54, 50)            377600    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 54, 50)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 50, 64)            16064     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 12, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 426753 (1.63 MB)\n",
      "Trainable params: 49153 (192.00 KB)\n",
      "Non-trainable params: 377600 (1.44 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Buildidng architecture \n",
    "model = tf.keras.Sequential([ \n",
    "\ttf.keras.layers.Embedding(vocab_size1+1, embedding_dim, \n",
    "\t\t\t\t\t\t\tinput_length=max_length, weights=[ \n",
    "\t\t\t\t\t\t\t\tembeddings_matrix], \n",
    "\t\t\t\t\t\t\ttrainable=False), \n",
    "\ttf.keras.layers.Dropout(0.2), \n",
    "\ttf.keras.layers.Conv1D(64, 5, activation='relu'), \n",
    "\ttf.keras.layers.MaxPooling1D(pool_size=4), \n",
    "\ttf.keras.layers.LSTM(64), \n",
    "\ttf.keras.layers.Dense(1, activation='sigmoid') \n",
    "]) \n",
    "model.compile(loss='binary_crossentropy', \n",
    "\t\t\toptimizer='adam', metrics=['accuracy']) \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9a66ee-a78a-403b-82c4-9f16294e6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the number of epochs for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b01be691-f3d1-4ffd-b6a4-2deac239cb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harb\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:635: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harb\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\keras\\src\\engine\\training_utils_v1.py:50: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harb\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700/2700 - 3s - loss: 0.6382 - accuracy: 0.6133 - val_loss: 0.5409 - val_accuracy: 0.6833 - 3s/epoch - 964us/sample\n",
      "Epoch 2/10\n",
      "2700/2700 - 1s - loss: 0.5736 - accuracy: 0.6937 - val_loss: 0.5356 - val_accuracy: 0.7200 - 967ms/epoch - 358us/sample\n",
      "Epoch 3/10\n",
      "2700/2700 - 1s - loss: 0.5256 - accuracy: 0.7437 - val_loss: 0.5093 - val_accuracy: 0.7100 - 987ms/epoch - 365us/sample\n",
      "Epoch 4/10\n",
      "2700/2700 - 1s - loss: 0.4841 - accuracy: 0.7756 - val_loss: 0.4864 - val_accuracy: 0.7700 - 1s/epoch - 444us/sample\n",
      "Epoch 5/10\n",
      "2700/2700 - 2s - loss: 0.4314 - accuracy: 0.7937 - val_loss: 0.4864 - val_accuracy: 0.7567 - 2s/epoch - 626us/sample\n",
      "Epoch 6/10\n",
      "2700/2700 - 1s - loss: 0.3980 - accuracy: 0.8170 - val_loss: 0.4653 - val_accuracy: 0.7667 - 920ms/epoch - 341us/sample\n",
      "Epoch 7/10\n",
      "2700/2700 - 1s - loss: 0.3491 - accuracy: 0.8507 - val_loss: 0.5434 - val_accuracy: 0.7467 - 1s/epoch - 464us/sample\n",
      "Epoch 8/10\n",
      "2700/2700 - 4s - loss: 0.3484 - accuracy: 0.8485 - val_loss: 0.4695 - val_accuracy: 0.7533 - 4s/epoch - 1ms/sample\n",
      "Epoch 9/10\n",
      "2700/2700 - 1s - loss: 0.2861 - accuracy: 0.8811 - val_loss: 0.4868 - val_accuracy: 0.7600 - 1s/epoch - 393us/sample\n",
      "Epoch 10/10\n",
      "2700/2700 - 1s - loss: 0.2689 - accuracy: 0.8900 - val_loss: 0.4990 - val_accuracy: 0.7733 - 964ms/epoch - 357us/sample\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "training_padded = np.array(training_sequences1) \n",
    "training_labels = np.array(training_labels) \n",
    "testing_padded = np.array(test_sequences1) \n",
    "testing_labels = np.array(test_labels) \n",
    "\n",
    "history = model.fit(training_padded, training_labels, \n",
    "\t\t\t\t\tepochs=num_epochs, \n",
    "\t\t\t\t\tvalidation_data=(testing_padded, \n",
    "\t\t\t\t\t\t\t\t\ttesting_labels), \n",
    "\t\t\t\t\tverbose=2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc90125-920f-4ec8-a992-1f897ef619ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "The model's accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dfd40f6-4800-4733-8ffd-1aec7fc5636d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harb\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This news is True\n"
     ]
    }
   ],
   "source": [
    "# sample text to check if fake or not \n",
    "X = \"Trump is black\"\n",
    "\n",
    "# detection \n",
    "sequences = tokenizer1.texts_to_sequences([X])[0] \n",
    "sequences = pad_sequences([sequences], maxlen=54, \n",
    "\t\t\t\t\t\tpadding=padding_type, \n",
    "\t\t\t\t\t\ttruncating=trunc_type) \n",
    "if(model.predict(sequences, verbose=0)[0][0] >= 0.5): \n",
    "\tprint(\"This news is True\") \n",
    "else: \n",
    "\tprint(\"This news is false\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9579fff-0146-4a73-ad98-cfc268484d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
